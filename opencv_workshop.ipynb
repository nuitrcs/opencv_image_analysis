{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b87e962-417b-4990-abb0-fc23b4cf83de",
   "metadata": {},
   "source": [
    "# Image Analysis with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368683d-1a83-416c-845a-02d05df64b77",
   "metadata": {},
   "source": [
    "## Overview - working with images in Python\n",
    "### What Is Image Analysis?\n",
    "\n",
    "Image analysis involves extracting meaningful information from images. In biomedical research, this could mean:\n",
    "* Counting cells in microscopy images\n",
    "* Measuring areas or shapes of tissues\n",
    "* Detecting fluorescence signals or tracking particles\n",
    "\n",
    "Python, with libraries like OpenCV, scikit-image, and Pillow, is widely used for this due to its flexibility, reproducibility, and integration with data science tools.\n",
    "\n",
    "### How Images Are Stored\n",
    "* Images are stored as arrays of pixels. \n",
    "* Each pixel represents a color or intensity value, depending on the image type:\n",
    "    - _Grayscale_: 2D array (height × width)\n",
    "    - _Color_ : 3D array (height × width × color_channels)\n",
    "\n",
    "For example, an RGB image of size 256×256 will be represented as a NumPy array with shape (256, 256, 3).\n",
    "\n",
    "### Color channels\n",
    "Each color image contains channels:\n",
    "* Red, Green, and Blue in standard images (RGB)\n",
    "* In OpenCV, images are read in BGR format by default, not RGB\n",
    "* Grayscale images use a single intensity channel (0–255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b28bcc-4c79-4d1d-9d62-3e35b19c1779",
   "metadata": {},
   "source": [
    "## Install OpenCV\n",
    "You can install either the main package, or the contrib version which has community contributed code in addition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aefc25-2e89-4ab1-abef-9f7973d4e930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install opencv\n",
    "# !pip install opencv-python\n",
    "\n",
    "# install the contrib version of opencv, along with opencv\n",
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d53b23f-72f9-4fb9-b7af-5ba8ea56b32d",
   "metadata": {},
   "source": [
    "Ideally, you want to build a new environment as follows:<br>\n",
    "`conda create -n OPENCV python=3.10 jupyterlab numpy pandas matplotlib seaborn -y` <br>\n",
    "`pip install opencv-contrib-python`\n",
    "Then activate your environment:<br>\n",
    "`conda activate OPENCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfdfe2b-b686-4970-b6cf-36967195b63e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a2c584-f76a-4525-9116-e9ed109810d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting some figure display paramaters\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white', {'axes.linewidth': 0.25})\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['xtick.major.size'] = 3\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['legend.edgecolor'] = 'w'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3ea21-6407-4433-be88-7cb70661d8a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Research task\n",
    "* __Question__\n",
    "You are interested in understanding the mechanisms of cancer. You decide to study regulators of cell-division in a human cell line to understand which genes might be involved.\n",
    "* __Dataset__ You have a publicly available dataset from [Moffat et al. (Cell 2006)](https://www.cell.com/fulltext/S0092-8674(06)00238-8) where Human HT29 colon-cancer cells were treated with RNAi molecules targeting specific genes. Microscopy images of these cells were taken. The full dataset is at [BBBC017](https://bbbc.broadinstitute.org/BBBC017/). \n",
    "* __Approach__ You want to calculate the percentage of cells that are neoplastic i.e. actively dividing for each gene that was tested in the screen<br>\n",
    "  - Aim 1: Count the total number of cells in an image\n",
    "  - Aim 2: Count the number of dividing cells in an image\n",
    "  - Aim 3: Find the average rate of cell-division for each gene targeted, and compare to the untargeted control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45e8b0-5b7a-48b7-b163-7dbbabaa5b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T09:35:02.359363Z",
     "iopub.status.busy": "2025-05-05T09:35:02.358370Z",
     "iopub.status.idle": "2025-05-05T09:35:02.373158Z",
     "shell.execute_reply": "2025-05-05T09:35:02.372467Z",
     "shell.execute_reply.started": "2025-05-05T09:35:02.359288Z"
    }
   },
   "source": [
    "In the example image above from [Moffat et al. (Cell 2006)](https://www.cell.com/fulltext/S0092-8674(06)00238-8), phospho-H3 marks actively dividing cells. The first row is the control, and the second row is cells treated with a RNAi molecule targeting the gene PLK1, a known cell-cylce regulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba3b2e-5e24-4b2d-b500-4e6d27a6440c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Image(\"images/example_images_moffat_2006.png\", width = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4dab2-477b-4c52-a47a-21c1250e7f8a",
   "metadata": {},
   "source": [
    "This full dataset consists of millions of images.\n",
    "A small subset of the data are available in the Broad Bioimage Benchmark Collection at [BBBC0001](https://bbbc.broadinstitute.org/BBBC001). <br>\n",
    "This contains a few different images of the nuclei channel only for a specific targeted gene. We will complete Aim 1 today!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092ea76-7b80-4e4b-8391-bdb43af6fcc8",
   "metadata": {},
   "source": [
    "## Let's look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed49bc-43f0-4e0e-af06-7946c305471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metadata file for experiment \n",
    "meta = pd.read_excel(\"data/BBBC017_v1_metadata.xls\")\n",
    "# subset the columns of interest\n",
    "meta = meta[['384-Plate#', '384-well', 'senseOligoId', 'location', 'gene name', 'Transcript Description']]\n",
    "# look at a random sample of 10 rows\n",
    "meta.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cbdfab-fe59-414b-84d6-36f82f85ff60",
   "metadata": {},
   "source": [
    "A small subset of the data are available in the Broad Bioimage Benchmark Collection at [BBBC0001](https://bbbc.broadinstitute.org/BBBC001). <br>\n",
    "This contains a few different images of the nuclei channel only for a specific targeted gene. <br>\n",
    "For this workshop, we will work with these images, located in the \"human_ht29_colon_cancer_1\" folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e96dab-4a3f-455e-a863-2c8255ceefeb",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Basic Image Operations</span> \n",
    "Here are some common tasks that one might think to do for this image analysis:\n",
    "- __read__ the image file\n",
    "- __display__ the image file\n",
    "- __convert__ the image file format to color or grayscale\n",
    "- find image __properties__ such as size, dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebfab0-54e8-4147-89a7-189e6a076469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an image file\n",
    "img = cv2.imread(\"data/color_image.jpeg\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a95f1b-ee40-481d-bab5-963ee7a41551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the image\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e3f29-631b-4f48-b33a-5fd478d4af45",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">__EXERCISE 1__</span> <br>\n",
    "Does the image above look like the original image saved in our folder? If not, what is different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd7c3f-2d07-4f8f-ad85-6f9ff9e61a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here #\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d9dc19-7fbb-4a18-b18c-6d3586c36611",
   "metadata": {},
   "source": [
    "Let's see how we can fix this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1d18e-8edc-4ca7-9875-767041a7f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an image file in the desired format\n",
    "img = cv2.imread(\"data/color_image.jpeg\", cv2.IMREAD_COLOR_RGB)\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a879c7-e49b-4081-9341-e25d04df1c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:20:55.480617Z",
     "iopub.status.busy": "2025-05-05T11:20:55.480062Z",
     "iopub.status.idle": "2025-05-05T11:20:55.488735Z",
     "shell.execute_reply": "2025-05-05T11:20:55.487910Z",
     "shell.execute_reply.started": "2025-05-05T11:20:55.480580Z"
    }
   },
   "source": [
    "Notice, the pixel positions / indices for the width and height of the image. <br>\n",
    "Why did colors show up in our grayscale image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40b354-8c99-4b22-94b3-19eb77896dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an image file in grayscale\n",
    "img = cv2.imread(\"data/color_image.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    "print(img.shape)\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2a06e-6cd7-4707-a6d7-d3f0e12147b8",
   "metadata": {},
   "source": [
    "Why is there color in my grayscale image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2624deb-8f62-4bbc-bdae-b88371ba327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img, cmap = \"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe02120-c5ab-42a1-8d5f-8a51b8f7a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your image to disk\n",
    "status = cv2.imwrite(\"data/grayscale_image.jpeg\",img)  \n",
    "print(\"Image written sucess? : \", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3508b-b978-49a0-a20b-966eaade1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your image to disk as a TIFF\n",
    "status = cv2.imwrite(\"data/grayscale_image.tiff\",img)  \n",
    "print(\"Image written sucess? : \", status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d1ef0b-8606-4abe-9aca-2deaae73f98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T13:29:44.810634Z",
     "iopub.status.busy": "2025-05-05T13:29:44.810045Z",
     "iopub.status.idle": "2025-05-05T13:29:44.816974Z",
     "shell.execute_reply": "2025-05-05T13:29:44.815402Z",
     "shell.execute_reply.started": "2025-05-05T13:29:44.810599Z"
    }
   },
   "source": [
    "<span style=\"color:orange\">__EXERCISE 2__</span> <br>\n",
    "The data from the RNAi screen is inside a folder named \"human...\". <br>\n",
    "- Read an image with cv2 in grayscale format.\n",
    "- What is the shape/size of the image.\n",
    "- Plot the image to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a33a50-8d0a-49a0-9a29-1b480f7bf62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# read an image from the human colon cancer folder\n",
    "my_img = \n",
    "\n",
    "# image size\n",
    "print(my_img.___)\n",
    "\n",
    "# plot the image\n",
    "plt.figure(figsize=(3,3))\n",
    "plt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194ea13-34f7-478d-bcd4-4eca06c1e57f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T13:39:47.779703Z",
     "iopub.status.busy": "2025-05-05T13:39:47.778960Z",
     "iopub.status.idle": "2025-05-05T13:39:47.788650Z",
     "shell.execute_reply": "2025-05-05T13:39:47.786512Z",
     "shell.execute_reply.started": "2025-05-05T13:39:47.779655Z"
    }
   },
   "source": [
    "### <span style=\"color:crimson\">Color channel operations</span> \n",
    "Here are some common tasks that one might think to for multi-channel color images:\n",
    "- __split__ the channels into separate files\n",
    "- __recolor__ the image file\n",
    "- __merge__ multiple channels into a single color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcc3b2-95e9-44eb-bfaa-29281f62022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read color image\n",
    "img = cv2.imread(\"data/color_image.jpeg\", cv2.IMREAD_COLOR_RGB)\n",
    "r, g, b = cv2.split(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a4159-f102-4c82-ada1-00f0dbbc3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b63bf6-c3b3-4954-afec-6a3fe9121554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at a single channnel now\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(r)\n",
    "plt.axis('off');\n",
    "plt.title('red')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(g)\n",
    "plt.axis('off');\n",
    "plt.title('green')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(b)\n",
    "plt.title('blue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb6a68-f504-4b8a-b685-317b277c9c07",
   "metadata": {},
   "source": [
    "Typically, you will do image analysis on single channels. So this is a useful operation. You might even want to save these split channel images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae2d07-d692-4871-9380-9832ab685430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T13:45:23.227199Z",
     "iopub.status.busy": "2025-05-05T13:45:23.226184Z",
     "iopub.status.idle": "2025-05-05T13:45:23.253137Z",
     "shell.execute_reply": "2025-05-05T13:45:23.252723Z",
     "shell.execute_reply.started": "2025-05-05T13:45:23.227123Z"
    }
   },
   "source": [
    "<span style=\"color:orange\">__EXERCISE 3__</span> <br>\n",
    "Save only the blue channel as a tiff file to the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e5325-bef0-4a6d-8522-45ce400392b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80deb27e-6ba3-4316-a27e-f2b244fb0012",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Pixel operations</span> \n",
    "Usually, for quantification, we care about the intensity of the pixels. For example, in the image above we can see that the nuclei are brighter than the background. Alternatively, we might want to access certain pixels for modification. <br>\n",
    "Let's look at the pixel intensities of the blue channel image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a6bd2-e981-4e68-a417-34a13224450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate histogram\n",
    "hist = cv2.calcHist([b], # list of images\n",
    "                    [0], # channel\n",
    "                    None, # mask\n",
    "                    [256], # histogram size\n",
    "                    [0, 256]) # range of values\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5,2))\n",
    "plt.plot(hist, color='black')\n",
    "plt.title('Blue channel Histogram')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4268c3-c120-4f57-90fc-cb1e1158f5dc",
   "metadata": {},
   "source": [
    "Suppose we want to find out the histogram only closer to the center of the image where there is a bright spot.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445befa-1dbe-4b34-be05-b3885c59e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_cropped = b[400:600, 400:600]\n",
    "plt.imshow(b_cropped);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f26cda-71d5-4cbd-b1c7-d10a6cc77fea",
   "metadata": {},
   "source": [
    "Alternatively, you can also mask out this region by setting the values to 0 or some minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d68a8-14d2-4296-b06f-0d404e0cd9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = b.copy()\n",
    "b1[400:600, 400:600] = b.min()\n",
    "plt.imshow(b1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241132f-a044-44f8-8b08-0c2d5b7f9d79",
   "metadata": {},
   "source": [
    "Images are essentially numpy arrays - you can do pixelwise math operations on them the same way as arrays! <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c53fa8-213b-4509-83d7-645120021893",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">__EXERCISE 4__</span> __Image background subtraction__<br>\n",
    "- Read in a colon cancer image in grayscale\n",
    "- Calculate the median pixel intensity\n",
    "- Subtract this median intensity from the image (remember to reset negative values to zero as `arr[arr < 0] = `)\n",
    "- Display the raw and background corrected image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353f806-8698-4438-81ae-7321e46a85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a83ed-4edd-4102-9a86-0c273a0cd0fc",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Preprocessing & Filtering</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8029c08-2853-4db5-91a6-acb17331e3e6",
   "metadata": {},
   "source": [
    "Raw images are more amenable to computational processing once they have been pre-processed to maintain image quality or to enhance feature detection. <br>\n",
    "* __Image smoothing__ - to remove noise in an image. This can be done by averaging, gaussian blur, median blur filters\n",
    "* __Thresholding__ - to remove background or to better detect objects of intereste. This could be global or adaptive i.e. local to the image region\n",
    "* __Edge detection__ - to detect edges of an image, which are usually bounding boxes of features of interest for segmentation\n",
    "* __Morphological operations__ - such as erosion, dilation to separate detected object clusters for example <br>\n",
    "Several of these take advantage of kernels or [convolution matrices](https://www.wikiwand.com/en/articles/Kernel_(image_processing))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7f624-bb8b-4c91-9396-2156ef445f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian blur to image\n",
    "blurred = cv2.GaussianBlur(b, # image source\n",
    "                           (31, 31), # kernel size (w, h), must be odd positive\n",
    "                           0, 0, # std deviation in X direction, td deviation in y direction\n",
    "                          cv2.BORDER_DEFAULT) # interpolation method\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(b)\n",
    "plt.axis('off');\n",
    "plt.title('raw')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(blurred)\n",
    "plt.axis('off');\n",
    "plt.title('blurred');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e31e5-f3b7-4c6f-88ce-53b795b6611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding - simple\n",
    "# All pixel values above 30 are set to 255, the rest to 0\n",
    "ret, thresh = cv2.threshold(b, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(b)\n",
    "plt.axis('off');\n",
    "plt.title('raw')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(thresh)\n",
    "plt.axis('off');\n",
    "plt.title('thresholded');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf59243-3ecf-47a6-a294-bd1a1715ee9e",
   "metadata": {},
   "source": [
    "You can also combine both operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24cd81-915e-415e-877c-cafe313656be",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(b, # image source\n",
    "                           (31, 31), # kernel size (w, h), must be odd positive\n",
    "                           0, 0, # std deviation in X direction, td deviation in y direction\n",
    "                          cv2.BORDER_DEFAULT) # interpolation method\n",
    "\n",
    "#All pixel values above 127 are set to 255, the rest to 0\n",
    "ret, thresh = cv2.threshold(blurred, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(b)\n",
    "plt.axis('off');\n",
    "plt.title('raw')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(thresh)\n",
    "plt.axis('off');\n",
    "plt.title('thresholded after blur');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ca28f-074c-4538-8668-a46f1be137ee",
   "metadata": {},
   "source": [
    "Do you notice how blurring before thresholding helps with removing all the noisy pixels in the background!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66ed7b-e657-46b1-8304-3fd36cc4dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive thresholding after blurring\n",
    "adaptive_thresh = cv2.adaptiveThreshold(\n",
    "    blurred,                  # source image (grayscale)\n",
    "    255,                # max value to use with THRESH_BINARY\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C,  # or cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "    cv2.THRESH_BINARY,  # threshold type\n",
    "    11,                 # blockSize: size of pixel neighborhood (must be odd)\n",
    "    2                   # C: constant subtracted from the mean\n",
    ")\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(b)\n",
    "plt.axis('off');\n",
    "plt.title('raw')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(adaptive_thresh, 'gray')\n",
    "plt.axis('off');\n",
    "plt.title('thresholded');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa70eb1-df8f-4707-a2af-68eacb342754",
   "metadata": {},
   "source": [
    "Now we start to see how nuclear contours might be obtained!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea6765-9067-47b5-9e60-d7a52f880f70",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">__EXERCISE 5__</span> __Image filtering__<br>\n",
    "- Read in a colon cancer image in grayscale\n",
    "- Use Gaussian blur and/or thresholding to get a binary image with nuclei clearly separated\n",
    "- Display the raw and thresholded image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971cfcb-f8df-48e7-a2f2-43c9f9953e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178a6c5-43bd-4336-b2df-e4f2f7b1c74b",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Segmentation and Contour detection</span>\n",
    "Now that we have started getting an idea of how to isolate areas of the image that represent individual cells or nuclei (or other features of interest), we can start doing some science! But first, we need to label the areas as cell_1, cell_2, etc or get the contour i.e. bounding lines for each blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52275e-1e88-441e-9506-f8b91b21fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding contours\n",
    "contours, _ = cv2.findContours(thresh,                  # binary image source\n",
    "                               cv2.RETR_EXTERNAL,       # return only outermost contour - good for cell counting\n",
    "                               cv2.CHAIN_APPROX_SIMPLE) # efficient storage parameter / data compression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138e296-02a6-4d62-adb8-c1119ea62705",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contours) # how many blobs did it find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6bd99-ac83-4dfb-8e09-4ad1c5cd9c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out areas based on size - optional\n",
    "filtered_contours = [c for c in contours if cv2.contourArea(c) > 100]\n",
    "len(filtered_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcc67c-14db-4cad-b566-5e83510977ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the contours to make sure everything looks right!\n",
    "# Draw contours on a copy of the image\n",
    "img_contours = b.copy()\n",
    "cv2.drawContours(img_contours, contours, -1, (255), 2)  # 255 line intensity, thickness 2\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img_contours)\n",
    "plt.title(\"Contours of Detected Objects\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0b4fe-802d-47b8-8727-49f6ce3c3eeb",
   "metadata": {},
   "source": [
    "When working with contours in OpenCV, there are several helpful functions that allow you to analyze shape, area, perimeter, and geometry of detected objects.\n",
    "* `cv2.contourArea(contour)` - use it to filter out small objects or noise.\n",
    "* `cv2.arcLength(contour, closed)` - perimeter (arc length) of a contour; Use it to: identify elongated or compact objects, or compare shapes. Use it to: crop objects, compute aspect ratio, draw bounding boxes.\n",
    "* `cv2.boundingRect(contour)` - Finds the smallest upright (non-rotated) rectangle that bounds the contour; \n",
    "* `cv2.minEnclosingCircle(contour)` - Finds the smallest circle that can enclose the contour. Use it to: detect roughly circular objects (like cells or nuclei).\n",
    "* `cv2.moments(contour)` - Computes image moments — used to calculate centroid, orientation, etc. Use it to: find the center of mass (centroid) of a shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a2e8c6-7579-4b7d-b9b5-ce9f271799a5",
   "metadata": {},
   "source": [
    "Of course - for our case study, simply counting the number of objects detected in also useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89e1b6-bd90-49de-a2bd-dbc9d0bb5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the nuclear areas detected in the image\n",
    "areas = [cv2.contourArea(c) for c in filtered_contours]\n",
    "plt.hist(areas);\n",
    "plt.xlabel('Nuclear area in pixels');\n",
    "plt.ylabel(\"Count\");\n",
    "plt.title(\"Nuclear Area\");\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1c0b4-1ea8-443a-8a80-b9072101d487",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">__EXERCISE 6__</span> __Contour detection and quantification__<br>\n",
    "- Read in a colon cancer image in grayscale\n",
    "- Use Gaussian blur and/or thresholding to get a binary image with nuclei clearly separated\n",
    "- Find the contours,\n",
    "- Filter the contours by area (or other morphological properties of the detected blobs)\n",
    "- Count the number of nuclei you detect for each of the 6 colon cancer images\n",
    "- Compare your counts to 2 manual experts for each image - [manual count data](https://data.broadinstitute.org/bbbc/BBBC001/BBBC001_v1_counts.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f9e23-8ee5-40bc-834b-025eae537bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "\n",
    "# compare to manual counting numbers - how far off was your computational pipeline?\n",
    "\n",
    "# compare your counts to your neighbor - what did you do differently?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f8349-c7d8-46d1-bdbc-f1854c8b8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS -- can you write a function to process each image in the folder and save the counts in a list one by one?\n",
    "# hint: use os.listdir() to get all the files in a directory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
